{
    "title": "Cheerio Crawler input",
    "type": "object",
    "schemaVersion": 1,
    "properties": {
        "startUrls": {
            "title": "Start URLs",
            "type": "array",
            "description": "URLs to start with",
            "prefill": [
                { "url": "http://example.com" },
                { "url": "http://example.com/some-path" }
            ],
            "editor": "requestListSources"
        },
        "pseudoUrls": {
            "title": "Pseudo-URLs",
            "type": "array",
            "description": "Pseudo-URLs matching requests you want to enqueue",
            "editor": "pseudoUrls"
        },
        "pageFunction": {
            "title": "Page function",
            "type": "string",
            "description": "Function executed for each request",
            "prefill": "async (context) => {\n  return context.$('title').text();\n\n}",
            "editor": "javascript"
        },
        "useRequestQueue": {
            "title": "Use request queue",
            "type": "boolean",
            "description": "Request queue enables recursive crawling.",
            "default": false,
            "groupCaption": "Options",
            "groupDescription": "Crawler settings"
        },
        "verboseLog": {
            "title": "Verbose log",
            "type": "boolean",
            "description": "Debug messages will be included in the log.",
            "default": false
        },
        "ignoreSslErrors": {
            "title": "Ignore SSL errors?",
            "type": "boolean",
            "description": "Crawler will ignore SSL certificate errors.",
            "default": false
        },
        "clickableElementsSelector": {
            "title": "Clickable elements selector",
            "type": "string",
            "description": "CSS selector matching elements to be clicked.",
            "editor": "textfield",
            "default": "a"
        },
        "maxPagesPerCrawl": {
            "title": "Maximum number of pages to crawl",
            "type": "integer",
            "description": "Maximum number of pages that the crawler will open.",
            "minimum": 0,
            "unit": "Pages"
        },
        "minConcurrency": {
            "title": "Minimum number of parallel scraping jobs.",
            "type": "integer",
            "description": "Maximum number of pages that the crawler will open.",
            "minimum": 1,
            "default": 5,
            "maximum": 20,
            "unit": "Parallels"
        },
        "maxConcurrency": {
            "title": "Maximum number of parallel scraping jobs.",
            "type": "integer",
            "description": "Maximum number of pages that the crawler will open.",
            "minimum": 1,
            "default": 25,
            "maximum": 250,
            "unit": "Parallels"
        }
    },
    "required": ["startUrls", "pageFunction", "maxPagesPerCrawl"]
}
